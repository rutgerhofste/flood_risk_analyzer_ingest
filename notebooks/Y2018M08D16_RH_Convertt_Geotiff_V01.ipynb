{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC2_INPUT_PATH: /volumes/data/Y2018M08D08_RH_S3_EC2_V01/output_V01/\n",
      "ec2_output_path: /volumes/data/Y2018M08D16_RH_Convertt_Geotiff_V01/output_V04/ \n",
      "s3_output_path: s3://wri-projects/Aqueduct30/processData/Y2018M08D16_RH_Convertt_Geotiff_V01/output_V04/ \n",
      "GCS_OUTPUT_PATH:gs://aqueduct30_v01/Y2018M08D16_RH_Convertt_Geotiff_V01/output_V04/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert the netCDF files to Geotiff and metadata file.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TESTING = 0\n",
    "\n",
    "SCRIPT_NAME = \"Y2018M08D16_RH_Convertt_Geotiff_V01\"\n",
    "OUTPUT_VERSION = 4\n",
    "\n",
    "EC2_INPUT_PATH = \"/volumes/data/Y2018M08D08_RH_S3_EC2_V01/output_V01/\"\n",
    "GCS_OUTPUT_PATH = \"gs://aqueduct30_v01/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "\n",
    "print(\"EC2_INPUT_PATH: \" + EC2_INPUT_PATH + \n",
    "      \"\\nec2_output_path: \" + ec2_output_path,\n",
    "      \"\\ns3_output_path: \" + s3_output_path,\n",
    "      \"\\nGCS_OUTPUT_PATH:\" + GCS_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M08D17 UTC 09:16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/volumes/data/Y2018M08D16_RH_Convertt_Geotiff_V01/output_V04/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r {ec2_output_path}\n",
    "!mkdir -p {ec2_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "try:\n",
    "    from osgeo import ogr, osr, gdal\n",
    "except:\n",
    "    sys.exit('ERROR: cannot find GDAL/OGR modules')\n",
    "\n",
    "if 'GDAL_DATA' not in os.environ:\n",
    "    os.environ['GDAL_DATA'] = r'/usr/share/gdal/2.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filename_to_dict(filename):\n",
    "    values = filename.split(\"_\")\n",
    "    \n",
    "    value_length = len(values)\n",
    "    \n",
    "    if value_length == 5:\n",
    "        keys = [\"floodtype\",\"climate\",\"model\",\"year\",\"returnperiod\"]\n",
    "        dictje = dict(zip(keys,values))\n",
    "    elif value_length == 6:\n",
    "        keys = [\"floodtype\",\"climate\",\"subsidence\",\"year\",\"returnperiod\",\"returnperiod_decimal\"]\n",
    "        dictje = dict(zip(keys,values))\n",
    "    elif value_length == 8:\n",
    "        keys = [\"floodtype\",\"climate\",\"subsidence\",\"year\",\"returnperiod\",\"returnperiod_decimal\",\"model\",\"sea_level_rise_scenario\"]\n",
    "        dictje = dict(zip(keys,values))\n",
    "    else:\n",
    "        print(\"error\")        \n",
    "    return dictje\n",
    "\n",
    "def ncdump(nc_fid):\n",
    "    '''ncdump outputs dimensions, variables and their attribute information.\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    The information is similar to that of NCAR's ncdump utility.\n",
    "    ncdump requires a valid instance of Dataset.\n",
    "\n",
    "    Args:\n",
    "        nc_fid (netCDF4.Dataset) : A netCDF4 dateset object\n",
    "\n",
    "    Returns:\n",
    "        nc_attrs (list) : A Python list of the NetCDF file global attributes.\n",
    "        nc_dims (list) : A Python list of the NetCDF file dimensions.\n",
    "        nc_vars (list) : A Python list of the NetCDF file variables.\n",
    "    '''\n",
    "\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
    "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
    "    return nc_attrs, nc_dims, nc_vars\n",
    "\n",
    "def get_global_attributes(dictje):\n",
    "    \"\"\" Get global attributes from netcdf\n",
    "    \n",
    "    Args:\n",
    "        dictionary with root, filename and properties.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_path = os.path.join(dictje[\"root\"],dictje[\"filename\"])\n",
    "    nc_fid = netCDF4.Dataset(input_path, 'r')\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_fid)\n",
    "    \n",
    "    global_attributes_dict = {}\n",
    "    for nc_attr in nc_attrs:\n",
    "        global_attributes_dict[nc_attr] = nc_fid.getncattr(nc_attr)\n",
    "        \n",
    "    \n",
    "    return global_attributes_dict\n",
    " \n",
    "def get_variable_attributes(dictje):\n",
    "    \"\"\" Get global attributes from netcdf\n",
    "    \n",
    "    Args:\n",
    "        dictionary with root, filename and properties.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_path = os.path.join(dictje[\"root\"],dictje[\"filename\"])\n",
    "    nc_fid = netCDF4.Dataset(input_path, 'r')\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_fid)\n",
    "    parameter = nc_vars[-1] #warning, project dependent\n",
    "    \n",
    "    variable_attrs = nc_fid.variables[parameter].ncattrs()\n",
    "    \n",
    "    variable_attributes_dict = {}\n",
    "    for variable_attr in variable_attrs:\n",
    "            variable_attributes_dict[parameter+\"_\"+variable_attr] = nc_fid.variables[parameter].getncattr(variable_attr)\n",
    "    \n",
    "    \n",
    "    return variable_attributes_dict\n",
    "\n",
    "def write_geotiff(output_path,geotransform,geoprojection,data,nodata_value=-9999,datatype=gdal.GDT_Float32):\n",
    "    \n",
    "    \"\"\" Write data to geotiff file\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    Args: \n",
    "        output_path (string) : output_path \n",
    "        geotransform (tuple) : geotransform\n",
    "        geoprojection (string) : geoprojection in osr format\n",
    "        data (np.array) : numpy array    \n",
    "        nodata_value (integer) : NoData value\n",
    "        datatype (GDAL datatype)\n",
    "    \n",
    "    \"\"\"  \n",
    "    \n",
    "    (x,y) = data.shape\n",
    "    format = \"GTiff\"\n",
    "    driver = gdal.GetDriverByName(format)\n",
    "    # you can change the dataformat but be sure to be able to store negative values including -9999\n",
    "    dst_ds = driver.Create(output_path,y,x,1,datatype, [ 'COMPRESS=LZW' ])\n",
    "    dst_ds.GetRasterBand(1).SetNoDataValue(nodata_value)\n",
    "    dst_ds.GetRasterBand(1).WriteArray(data)\n",
    "    dst_ds.SetGeoTransform(geotransform)\n",
    "    dst_ds.SetProjection(geoprojection)\n",
    "    dst_ds = None\n",
    "    return 1\n",
    "\n",
    "def get_global_georeference(array):\n",
    "    \"\"\" Get the geotransform and projection for a numpy array\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    Returns a geotransform and projection for a global extent in epsg 4326 \n",
    "    projection.\n",
    "    \n",
    "    Args:\n",
    "        array (np.array) : numpy array\n",
    "    \n",
    "    Returns:\n",
    "        geotransform (tuple) : geotransform\n",
    "        geoprojection (string) : geoprojection in osr format    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    y_dimension = array.shape[0] #rows, lat\n",
    "    x_dimension = array.shape[1] #cols, lon\n",
    "    geotransform = (-180,360.0/x_dimension,0,90,0,-180.0/y_dimension)\n",
    "    \n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)\n",
    "    geoprojection = srs.ExportToWkt()\n",
    "    \n",
    "    if len(geoprojection) == 0:\n",
    "        warnings.warn(\"GDAL_DATA path not set correctly. Assert os.environ \" \\\n",
    "                      \"contains GDAL_DATA \\n\" \\\n",
    "                      \"Code will execute without projection set\")\n",
    "\n",
    "    return geotransform, geoprojection\n",
    "\n",
    "def standardize_time(time_unit,times):\n",
    "    \"\"\" Append standardize time to list\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    The netCDF results of the university of Utrecht consist of multiple time \n",
    "    formats. \n",
    "    \n",
    "    Args:\n",
    "        time_unit (string) : units as provided by the netCDF4 file. \n",
    "        times (list) : list of time in units provided in time_units (e.g. days).\n",
    "    \n",
    "    Returns:\n",
    "        standardized_time (list) : list of normalized times in datetime format.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    standardized_time =[]\n",
    "    for time in times:\n",
    "        if time_unit == (\"days since 1900-01-01 00:00:00\") or (time_unit ==\"Days since 1900-01-01\"):\n",
    "            standardized_time.append(datetime.datetime(1900,1,1) + datetime.timedelta(days=time))\n",
    "        elif time_unit == \"days since 1901-01-01 00:00:00\" or time_unit == \"Days since 1901-01-01\":\n",
    "            standardized_time.append(datetime.datetime(1901,1,1) + datetime.timedelta(days=time))\n",
    "        elif time_unit == \"Days since 1960-01-01 00:00:00\":\n",
    "            standardized_time.append(datetime.datetime(1960,1,1) + datetime.timedelta(days=time))    \n",
    "        else:\n",
    "            raise(\"Error, unknown format:\",time_unit)\n",
    "            standardized_time.append(-9999)\n",
    "    return standardized_time\n",
    "\n",
    "def convert_netcdf_geotiff(dictje):\n",
    "    \"\"\" Convert netcdf to geotiff\n",
    "    \n",
    "    Args:\n",
    "        dictionary with root, filename and properties.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_path = os.path.join(dictje[\"root\"],dictje[\"filename\"])\n",
    "    nc_fid = netCDF4.Dataset(input_path, 'r')\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_fid)\n",
    "    parameter = nc_vars[-1]\n",
    "    lats = nc_fid.variables['lat'][:]  # extract/copy the data\n",
    "    lons = nc_fid.variables['lon'][:]\n",
    "    times = nc_fid.variables['time'][:]\n",
    "    time_unit = nc_fid.variables[\"time\"].getncattr(\"units\")\n",
    "\n",
    "    standardized_time = standardize_time(time_unit,times)\n",
    "    \n",
    "    i = 0 # single time step\n",
    "    Z = nc_fid.variables[parameter][i, :, :]\n",
    "    Z[Z<-9990]= -9999\n",
    "    Z[Z>1e19] = -9999\n",
    "    \n",
    "    Z = np.flipud(Z) #depending on NetCDF type. \n",
    "    \n",
    "    base_filename, extension = dictje[\"filename\"].split(\".\")\n",
    "    output_filename = base_filename + \".tif\"    \n",
    "    output_path_geotiff = os.path.join(ec2_output_path,output_filename)    \n",
    "    geotransform, geoprojection = get_global_georeference(Z)    \n",
    "    write_geotiff(output_path_geotiff,geotransform,geoprojection,Z,nodata_value=-9999,datatype=gdal.GDT_Float32)\n",
    "    \n",
    "    return standardized_time  \n",
    "\n",
    "def pickle_dictionary(dictje):\n",
    "    base_filename, extension = dictje[\"filename\"].split(\".\")\n",
    "    output_filename = base_filename + \".pickle\"    \n",
    "    output_path_pickle = os.path.join(ec2_output_path,output_filename)   \n",
    "    \n",
    "    with open(output_path_pickle, 'wb') as handle:\n",
    "        pickle.dump(dictje, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = 0\n",
    "master_dict = {}\n",
    "for root, dirs, files in os.walk(EC2_INPUT_PATH):\n",
    "    for one_file in files:\n",
    "        if one_file.endswith(\"nc\"):\n",
    "            file_dict = {}\n",
    "            file_dict[\"root\"] = root\n",
    "            file_dict[\"filename\"] = one_file\n",
    "            filename , extension = one_file.split(\".\")\n",
    "            file_dict[\"properties_from_filename\"] = filename_to_dict(filename)\n",
    "            master_dict[ID] = file_dict\n",
    "            ID += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of files that need to be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n"
     ]
    }
   ],
   "source": [
    "print(len(master_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ID, dictje in master_dict.items():\n",
    "    master_dict[ID][\"global_attributes\"] = get_global_attributes(dictje)\n",
    "    master_dict[ID][\"variable_attributes\"] = get_variable_attributes(dictje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_items(dictje):\n",
    "    try:\n",
    "        convert_netcdf_geotiff(dictje)\n",
    "        pickle_dictionary(dictje)\n",
    "        print(dictje[\"filename\"])\n",
    "    except:\n",
    "        print(\"error\",dictje[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    n = 10\n",
    "    master_dict = {k: master_dict[k] for k in list(master_dict)[:n]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = mp.cpu_count()\n",
    "p= mp.Pool(3) # Memory issues, limiting processes to 3, using appr 60-80% memory\n",
    "processed_values= p.map( process_items, master_dict.values())  \n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r {ec2_output_path} {GCS_OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:  \n",
    "2:27:01.588096\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
